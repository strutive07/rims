# MATH-full_dt.math 
|    | model_name                  | cot                | pal                | p2c                | simple greedy     | cross_and_mix     | cross_and_mix_with_selection   |
|---:|:----------------------------|:-------------------|:-------------------|:-------------------|:------------------|:------------------|:-------------------------------|
|  1 | Mathstral-7B-v0.1           | 2112/5000 (42.2 %) | 1573/5000 (31.5 %) | 1370/5000 (27.4 %) | 0.464 (2319/5000) | 0                 | 0                              |
|  1 | Meta-Llama-3-8B-Instruct    | 1508/5000 (30.2 %) | 748/5000 (15.0 %)  | 1065/5000 (21.3 %) | 0.319 (1597/5000) | 0                 | 0                              |
|  1 | Meta-Llama-3.1-70B-Instruct | 3164/5000 (63.3 %) | 2870/5000 (57.4 %) | 2701/5000 (54.0 %) | 0.677 (3383/5000) | 0                 | 0                              |
|  1 | Phi-3-small-128k-instruct   | 1844/5000 (36.9 %) | 1908/5000 (38.2 %) | 1815/5000 (36.3 %) | 0.462 (2309/5000) | 0                 | 0                              |
|  1 | gpt-4o-mini                 | 3122/5000 (62.4 %) | 2736/5000 (54.7 %) | 2824/5000 (56.5 %) | 0.682 (3409/5000) | 0.595 (2974/5000) | 0.698 (3491/5000)              |


# ocw_course_dt.ocw 
|    | model_name                  | cot             | pal             | p2c             | simple greedy   |   cross_and_mix |   cross_and_mix_with_selection |
|---:|:----------------------------|:----------------|:----------------|:----------------|:----------------|----------------:|-------------------------------:|
|  1 | Mathstral-7B-v0.1           | 59/272 (21.7 %) | 23/272 (8.5 %)  | 26/272 (9.6 %)  | 0.213 (58/272)  |              0  |                             0  |
|  1 | Meta-Llama-3-8B-Instruct    | 33/272 (12.1 %) | 7/272 (2.6 %)   | 18/272 (6.6 %)  | 0.129 (35/272)  |              0  |                             0  |
|  1 | Meta-Llama-3.1-70B-Instruct | 96/272 (35.3 %) | 77/272 (28.3 %) | 67/272 (24.6 %) | 0.360 (98/272)  |              0  |                             0  |
|  1 | Phi-3-small-128k-instruct   | 50/272 (18.4 %) | 24/272 (8.8 %)  | 26/272 (9.6 %)  | 0.199 (54/272)  |              0  |                             0  |
|  1 | gpt-4o-mini                 | 35/272 (12.9 %) | 60/272 (22.1 %) | 58/272 (21.3 %) | 0.221 (60/272)  |              0  |                             0  |


# gsm8K_test_dt.gsm 
|    | model_name                  | cot                | pal                | p2c                | simple greedy     |   cross_and_mix |   cross_and_mix_with_selection |
|---:|:----------------------------|:-------------------|:-------------------|:-------------------|:------------------|----------------:|-------------------------------:|
|  1 | Mathstral-7B-v0.1           | 1009/1319 (76.5 %) | 1014/1319 (76.9 %) | 968/1319 (73.4 %)  | 0.848 (1118/1319) |              0  |                             0  |
|  1 | Meta-Llama-3-8B-Instruct    | 963/1319 (73.0 %)  | 1002/1319 (76.0 %) | 859/1319 (65.1 %)  | 0.814 (1074/1319) |              0  |                             0  |
|  1 | Meta-Llama-3.1-70B-Instruct | 1175/1319 (89.1 %) | 1245/1319 (94.4 %) | 1220/1319 (92.5 %) | 0.958 (1263/1319) |              0  |                             0  |
|  1 | Phi-3-small-128k-instruct   | 1113/1319 (84.4 %) | 1139/1319 (86.4 %) | 1068/1319 (81.0 %) | 0.906 (1195/1319) |              0  |                             0  |
|  1 | gpt-4o-mini                 | 1144/1319 (86.7 %) | 1193/1319 (90.4 %) | 1213/1319 (92.0 %) | 0.936 (1234/1319) |              0  |                             0  |


# SVAMP_dt.svamp 
|    | model_name                  | cot               | pal               | p2c               | simple greedy    |   cross_and_mix |   cross_and_mix_with_selection |
|---:|:----------------------------|:------------------|:------------------|:------------------|:-----------------|----------------:|-------------------------------:|
|  1 | Mathstral-7B-v0.1           | 857/1000 (85.7 %) | 910/1000 (91.0 %) | 877/1000 (87.7 %) | 0.930 (930/1000) |              0  |                             0  |
|  1 | Meta-Llama-3-8B-Instruct    | 827/1000 (82.7 %) | 870/1000 (87.0 %) | 568/1000 (56.8 %) | 0.852 (852/1000) |              0  |                             0  |
|  1 | Meta-Llama-3.1-70B-Instruct | 880/1000 (88.0 %) | 950/1000 (95.0 %) | 923/1000 (92.3 %) | 0.950 (950/1000) |              0  |                             0  |
|  1 | Phi-3-small-128k-instruct   | 833/1000 (83.3 %) | 923/1000 (92.3 %) | 631/1000 (63.1 %) | 0.927 (927/1000) |              0  |                             0  |
|  1 | gpt-4o-mini                 | 906/1000 (90.6 %) | 943/1000 (94.3 %) | 928/1000 (92.8 %) | 0.949 (949/1000) |              0  |                             0  |


