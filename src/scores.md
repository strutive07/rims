# MATH-full_dt.math 
|    | model_name                  | cot                | pal                | p2c                | simple greedy     | rims              | rims_disable_hinting   |
|---:|:----------------------------|:-------------------|:-------------------|:-------------------|:------------------|:------------------|:-----------------------|
|  1 | Mathstral-7B-v0.1           | 2111/5000 (42.2 %) | 1573/5000 (31.5 %) | 1370/5000 (27.4 %) | 0.464 (2318/5000) | 0.445 (2225/5000) | 0.445 (2225/5000)      |
|  1 | Meta-Llama-3-8B-Instruct    | 1508/5000 (30.2 %) | 748/5000 (15.0 %)  | 1065/5000 (21.3 %) | 0.319 (1597/5000) | 0.32 (1536/5000)  | 0.315 (1543/5000)      |
|  1 | Meta-Llama-3.1-70B-Instruct | 3164/5000 (63.3 %) | 2870/5000 (57.4 %) | 2701/5000 (54.0 %) | 0.677 (3383/5000) | 0.62 (3083/5000)  | 0.626 (3109/5000)      |
|  1 | Phi-3-small-128k-instruct   | 1842/5000 (36.8 %) | 1908/5000 (38.2 %) | 1815/5000 (36.3 %) | 0.462 (2308/5000) | 0.414 (2017/5000) | 0.424 (2121/5000)      |
|  1 | gpt-4o-mini                 | 45/5000 (0.9 %)    | 2736/5000 (54.7 %) | 2824/5000 (56.5 %) | 0.435 (2174/5000) | 0.46 (2301/5000)  | 0.456 (2281/5000)      |


# ocw_course_dt.ocw 
|    | model_name                  | cot             | pal             | p2c             | simple greedy   | rims           | rims_disable_hinting   |
|---:|:----------------------------|:----------------|:----------------|:----------------|:----------------|:---------------|:-----------------------|
|  1 | Mathstral-7B-v0.1           | 59/272 (21.7 %) | 23/272 (8.5 %)  | 26/272 (9.6 %)  | 0.213 (58/272)  | 0.184 (50/272) | 0.188 (47/272)         |
|  1 | Meta-Llama-3-8B-Instruct    | 33/272 (12.1 %) | 7/272 (2.6 %)   | 18/272 (6.6 %)  | 0.129 (35/272)  | 0.11 (30/272)  | 0.114 (28/272)         |
|  1 | Meta-Llama-3.1-70B-Instruct | 96/272 (35.3 %) | 77/272 (28.3 %) | 67/272 (24.6 %) | 0.360 (98/272)  | 0.301 (80/272) | 0.309 (81/272)         |
|  1 | Phi-3-small-128k-instruct   | 50/272 (18.4 %) | 24/272 (8.8 %)  | 26/272 (9.6 %)  | 0.199 (54/272)  | 0.165 (44/272) | 0.165 (43/272)         |
|  1 | gpt-4o-mini                 | 35/272 (12.9 %) | 60/272 (22.1 %) | 58/272 (21.3 %) | 0.221 (60/272)  | 0.232 (59/272) | 0.213 (58/272)         |


# gsm8K_test_dt.gsm 
|    | model_name                  | cot                | pal                | p2c                | simple greedy     | rims              | rims_disable_hinting   |
|---:|:----------------------------|:-------------------|:-------------------|:-------------------|:------------------|:------------------|:-----------------------|
|  1 | Mathstral-7B-v0.1           | 1009/1319 (76.5 %) | 1014/1319 (76.9 %) | 968/1319 (73.4 %)  | 0.848 (1118/1319) | 0.87 (1131/1319)  | 0.872 (1143/1319)      |
|  1 | Meta-Llama-3-8B-Instruct    | 963/1319 (73.0 %)  | 1002/1319 (76.0 %) | 859/1319 (65.1 %)  | 0.814 (1074/1319) | 0.831 (1084/1319) | 0.842 (1110/1319)      |
|  1 | Meta-Llama-3.1-70B-Instruct | 1175/1319 (89.1 %) | 1245/1319 (94.4 %) | 1220/1319 (92.5 %) | 0.958 (1263/1319) | 0.96 (1262/1319)  | 0.961 (1267/1319)      |
|  1 | Phi-3-small-128k-instruct   | 1113/1319 (84.4 %) | 1139/1319 (86.4 %) | 1068/1319 (81.0 %) | 0.906 (1195/1319) | 0.92 (1181/1319)  | 0.917 (1172/1319)      |
|  1 | gpt-4o-mini                 | 1144/1319 (86.7 %) | 1193/1319 (90.4 %) | 1213/1319 (92.0 %) | 0.936 (1234/1319) | 0.935 (1228/1319) | 0.936 (1233/1319)      |


# SVAMP_dt.svamp 
|    | model_name                  | cot               | pal               | p2c               | simple greedy    | rims             | rims_disable_hinting   |
|---:|:----------------------------|:------------------|:------------------|:------------------|:-----------------|:-----------------|:-----------------------|
|  1 | Mathstral-7B-v0.1           | 857/1000 (85.7 %) | 910/1000 (91.0 %) | 877/1000 (87.7 %) | 0.930 (930/1000) | 0.939 (939/1000) | 0.937 (937/1000)       |
|  1 | Meta-Llama-3-8B-Instruct    | 827/1000 (82.7 %) | 870/1000 (87.0 %) | 568/1000 (56.8 %) | 0.852 (852/1000) | 0.892 (892/1000) | 0.895 (895/1000)       |
|  1 | Meta-Llama-3.1-70B-Instruct | 880/1000 (88.0 %) | 950/1000 (95.0 %) | 923/1000 (92.3 %) | 0.950 (950/1000) | 0.957 (957/1000) | 0.96 (960/1000)        |
|  1 | Phi-3-small-128k-instruct   | 833/1000 (83.3 %) | 923/1000 (92.3 %) | 631/1000 (63.1 %) | 0.927 (927/1000) | 0.943 (943/1000) | 0.939 (939/1000)       |
|  1 | gpt-4o-mini                 | 906/1000 (90.6 %) | 943/1000 (94.3 %) | 928/1000 (92.8 %) | 0.949 (949/1000) | 0.952 (952/1000) | 0.952 (952/1000)       |


